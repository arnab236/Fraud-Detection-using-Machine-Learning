# FinSight: Financial Transaction Fraud Detection

A data science project focused on detecting fraudulent financial transactions using machine learning techniques.  
This project demonstrates a complete end-to-end pipeline â€” from data acquisition and preprocessing to model training, evaluation, and deployment via a Streamlit web application.

---

## ğŸ§  Overview

**FinSight** aims to identify potentially fraudulent financial transactions based on historical data.  
The initial implementation uses a **Logistic Regression** model, with future plans to integrate **Random Forest**, **XGBoost**, and **Neural Network** approaches for improved accuracy and robustness.

---

## ğŸ“‘ Table of Contents

1. [Project Structure](#project-structure)
2. [Features](#features)
3. [Installation](#installation)
4. [Usage](#usage)
5. [Data Source](#data-source)
6. [Modeling Workflow](#modeling-workflow)
7. [Streamlit App](#streamlit-app)
8. [Dependencies](#dependencies)
9. [Future Improvements](#future-improvements)
10. [License](#license)

---

## ğŸ—‚ï¸ Project Structure

```

ğŸ“ fraud-detection/
â”œâ”€â”€ analysis_model.ipynb        # Jupyter notebook for EDA, preprocessing, and model training
â”œâ”€â”€ dataset_from_kaggle.py      # Script for downloading/loading dataset from Kaggle
â”œâ”€â”€ fraud_detection.py          # Streamlit app for model inference and visualization
â”œâ”€â”€ models/                     # (Optional) Folder to store trained models (joblib files)
â”œâ”€â”€ data/                       # (Optional) Folder for raw or processed datasets
â””â”€â”€ README.md                   # Project documentation

````

---

## âœ¨ Features

- End-to-end machine learning pipeline:
  - Data extraction from Kaggle
  - Exploratory Data Analysis (EDA)
  - Feature engineering and preprocessing
  - Model training and evaluation
  - Deployment through a Streamlit dashboard
- Currently uses **Logistic Regression**
- Easy to extend with ensemble and deep learning models

---

## âš™ï¸ Installation

### 1. Clone the repository
```bash
git clone https://github.com/yourusername/fraud-detection.git
cd fraud-detection
````

### 2. Set up the environment

Install the required dependencies:

```bash
pip install -r requirements.txt
```

*(Create this file manually if not present â€” see the [Dependencies](#dependencies) section below.)*

---

## ğŸš€ Usage

### 1. Data Preparation

Ensure your Kaggle credentials are configured for `kagglehub`, then run:

```bash
python dataset_from_kaggle.py
```

### 2. Model Training & Evaluation

You can open the notebook in Jupyter and run all cells:

```bash
jupyter notebook analysis_model.ipynb
```

This will train the **Logistic Regression** model and save it (e.g., `model.joblib`).

### 3. Launch the Streamlit App

```bash
streamlit run fraud_detection.py
```

Visit the displayed local URL (usually `http://localhost:8501`) to interact with the model.

---

## ğŸ“Š Data Source

The dataset is obtained from **Kaggle**, containing anonymized features representing transaction patterns.
Each record is labeled as **fraudulent** (`1`) or **legitimate** (`0`).

---

## ğŸ§© Modeling Workflow

1. **Data Loading** â€” Using `kagglehub` to fetch data
2. **Preprocessing** â€” Scaling, encoding, and splitting using `scikit-learn` pipelines
3. **Model Training** â€” Logistic Regression baseline
4. **Evaluation** â€” Accuracy, Precision, Recall, F1-Score, ROC-AUC metrics
5. **Model Saving** â€” Using `joblib` for persistence
6. **Deployment** â€” Streamlit app for real-time inference

---

## ğŸ§¾ Dependencies

* Python 3.8+
* pandas
* numpy
* scikit-learn
* seaborn
* matplotlib
* streamlit
* joblib
* kagglehub

You can create a `requirements.txt` with:

```txt
pandas
numpy
scikit-learn
seaborn
matplotlib
streamlit
joblib
kagglehub
```

---

## ğŸ”® Future Improvements

* Add advanced models: Random Forest, XGBoost, Neural Networks
* Implement hyperparameter optimization
* Deploy app on cloud (Streamlit Cloud / AWS / GCP)
* Integrate explainability with SHAP or LIME
* Build REST API for real-time fraud prediction

---

## ğŸ§‘â€ğŸ’» Author

**Arnab Sarkar**
Personal Data Science Project â€” 2025

---

## ğŸ“„ License

This project is licensed under the **MIT License** 


---

Would you like me to include a **`requirements.txt` file** automatically (based on these dependencies) along with the README?
```
